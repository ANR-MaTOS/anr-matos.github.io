<!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>  La traduction du r√©glement europ√©en sur l‚ÄôIA | ùïÑaTOS
</title>
  <link rel="canonical" href="https://anr-matos.github.io/en/posts/2023/oct/01/la-traduction-du-reglement-europeen-sur-lia-fr.html">

    <link rel="apple-touch-icon" href="https://anr-matos.github.io/en/static/images/apple-touch-icon.png" sizes="180x180">
    <link rel="icon" type="image/png" href="https://anr-matos.github.io/en/static/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="https://anr-matos.github.io/en/static/images//favicon-16x16.png" sizes="16x16">
    <link rel="manifest" href="https://anr-matos.github.io/en/static/images/manifest.json">
    <meta name="theme-color" content="#333333">

  <link rel="stylesheet" media="screen" href="https://fontlibrary.org//face/linux-libertine" type="text/css"/>
  <link rel="stylesheet" href="https://anr-matos.github.io/en/./theme/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://anr-matos.github.io/en/./theme/css/fontawesome.min.css">
  <link rel="stylesheet" href="https://anr-matos.github.io/en/theme/css/pygments/default.min.css">
<link rel="stylesheet" href="https://anr-matos.github.io/en/theme/css/theme.css">

  <link rel="alternate" type="application/atom+xml" title="Full Atom Feed"
        href="https://anr-matos.github.io/feeds/all.atom.xml">
  <link rel="alternate" type="application/atom+xml" title="Categories Atom Feed"
        href="https://anr-matos.github.io/feeds/miscellaneous.atom.xml">  
  <meta name="description" content="La science se fait en anglais, mais le droit europ√©en, lui, se fait dans toutes les langues de l‚ÄôUnion. Parfois, il arrive que le droit parle de science, de science en train de se faire, comme dans le cas des projets de r√©glementation des syst√®mes d‚ÄôIntelligence Artificielle, qui ‚Ä¶">


</head>

<body>
<header class="header">


<nav class="navbar navbar-expand-md navbar-light shadow-sm">
<a class="navbar-brand" href="#"></a>
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav m-0 ml-auto p-0">
		<li class="nav-item m-0">
		  <a class="nav-link m-0" href="https://anr-matos.github.io/en/index.html" data-target="#about">
		    <span> Home</span>
		  </a>
		</li>
		<li class="nav-item m-0">
		  <a class="nav-link m-0" href="https://anr-matos.github.io/en/pages/background.html" data-target="#about">
		    <span> Background</span>
		  </a>
		</li>
		<li class="nav-item m-0">
		  <a class="nav-link m-0" href="https://anr-matos.github.io/en/pages/publications.html" data-target="#about">
		    <span> Publications</span>
		  </a>
		</li>
		<li class="nav-item m-0">
		  <a class="nav-link m-0" href="https://anr-matos.github.io/en/pages/resources.html" data-target="#about">
		    <span> Resources</span>
		  </a>
		</li>
		<li class="nav-item m-0">
		  <a class="nav-link m-0" href="https://anr-matos.github.io/en/pages/news.html" data-target="#about">
		    <span> News</span>
		  </a>
		</li>
		<li class="nav-item m-0">
		  <a class="nav-link m-0" href="https://anr-matos.github.io/en/archives.html" data-target="#about">
		    <span> Blog</span>
		  </a>
		</li>
		<li class="nav-item m-0">
		  <a class="nav-link m-0" href="https://anr-matos.github.io/en/pages/partners.html" data-target="#about">
		    <span> Partners</span>
		  </a>
		</li>
		<li class="nav-item m-0">
		  <a class="nav-link m-0" href="mailto:contact@anr-matos.fr" data-target="#about">
		    <span> Contact</span>
		  </a>
		</li>
		<li class="nav-item m-0">
		  <a class="nav-link m-0" href="https://twitter.com/anr_matos" data-target="#about">
		    <span><i class="fab fa-twitter" aria-hidden="true"></i></span>
		  </a>
		</li>
		<li class="nav-item m-0">
		  <a class="nav-link m-0" href="https://github.com/ANR-Matos" data-target="#about">
		    <span><i class="fab fa-github" aria-hidden="true"></i></span>
		  </a>
		</li>
	      </ul>
  </div>
  </nav>

    <div class="container">
<div class="row">
  
    <div class="col-sm-2 float-right">
      <!-- <a href="https://anr-matos.github.io/en/"> -->
        <img class="img-fluid rounded float-right" src=https://anr-matos.github.io/en/static/images/matos-logo.png width=160 height=160 alt="ùïÑaTOS">
      <!-- </a> -->
    </div>
  <div class="col-sm-10">
    <h1 class="title">
      <!-- <a href="https://anr-matos.github.io/en/"> -->
        ùïÑaTOS
      <!-- </a> -->
    </h1>
      <p class="text-muted subtitle">MAchine Translation for Open Science</p>


	
  </div>
</div>    </div>
  </header>

    <div class="main">

    <div class="container">
  <article class="article">
    <header>
      <ul class="list-inline">
        <li class="list-inline-item text-muted" title="2023-10-01T00:00:00+02:00">
          <i class="fas fa-clock"></i>
          Dim 01 oct 2023
        </li>
        <li class="list-inline-item">
          <i class="fas fa-folder-open"></i>
          <a href="https://anr-matos.github.io/en/category/miscellaneous.html">Miscellaneous</a>
        </li>
      </ul>
    </header>
    <div class="content">
      
      <p>La science se fait en anglais, mais le droit europ√©en, lui, se fait dans toutes les langues de l&#8217;Union. Parfois, il arrive que le droit parle de science, de science en train de se faire, comme dans le cas des projets de r√©glementation des syst√®mes d&#8217;Intelligence Artificielle, qui sont en cours de r√©flexion au sein des institutions europ√©ennes, et qui ont du √™tre amend√©s du fait de l&#8217;√©mergence des giga mod√®les de langue. Cette contribution illustre l&#8217;importance de disposer d&#8217;une terminologie √† jour pour parler clairement, dans des termes compr√©hensibles par le plus grand nombre, des technologies en train d&#8217;√©merger et des enjeux qu&#8217;elles&nbsp;posent.</p>
<hr>
<p>La <a href="https://eur-lex.europa.eu/legal-content/FR/ALL/?uri=CELEX%3A52021PC0206">L√©gislation europ√©enne sur l&#8217;intelligence artificielle</a> en cours d&#8217;√©laboration au sein des institutions de l&#8217;<span class="caps">UE</span> a connu une avanc√©e r√©cente avec le vote du parlement europ√©en le 14 juin 2023 d&#8217;un texte r√©vis√©, qui doit maintenant √™tre n√©goci√© avec le conseil et les √©tats&nbsp;membres.</p>
<p>Le texte adopt√© par les parlementaires est disponible sur le site du Parlement&nbsp;Europ√©en: </p>
<ul>
<li><a href="https://www.europarl.europa.eu/doceo/document/TA-9-2023-0236_EN.html">Version anglaise</a>, consult√©e le 19 juin&nbsp;2023</li>
<li><a href="https://www.europarl.europa.eu/doceo/document/A-9-2023-0188_FR.html">Version fran√ßaise</a>, consult√©e le 19 juin&nbsp;2023</li>
</ul>
<p>Nous commentons simplement quelques-uns des amendements les plus r√©cents, li√©s aux d√©veloppements des giga mod√®les de langue. Ces mod√®les posent un probl√®me √† l&#8217;√©quilibre g√©n√©ral du texte qui jusqu&#8217;√† pr√©sent avait soigneusement √©vit√© de d√©finir pr√©cis√©ment les technologies, en se focalisant sur les finalit√©s de celles-ci ; selon leur niveau de danger (du plus au moins risqu√©), la r√©glementation pr√©voyait d&#8217;augmenter le niveau d&#8217;encadrement, pouvant aller jusqu&#8217;√† l&#8217;interdiction totale des technologies les plus dangeureuses (par exemple la notation&nbsp;sociale). </p>
<p>Commen√ßons par l&#8217;amendement&nbsp;34.</p>
<table>
<thead>
<tr>
<th>Anglais</th>
<th>Fran√ßais</th>
</tr>
</thead>
<tbody>
<tr>
<td>(12c)  The developers of free and open-source <span class="caps">AI</span> components should not be mandated under this Regulation to comply with requirements targeting the <span class="caps">AI</span> value chain and, in particular, not towards the provider that has used that free and open-source <span class="caps">AI</span> component. Developers of free and open-source <span class="caps">AI</span> components should however be encouraged to implement widely adopted documentation practices, such as <strong>model and data cards</strong>, as a way to accelerate information sharing along the <span class="caps">AI</span> value chain, allowing the promotion of trustworthy <span class="caps">AI</span> systems in the Union.</td>
<td>(12 quater) Les d√©veloppeurs de composants d‚Äô<span class="caps">IA</span> libres et ouverts ne devraient pas √™tre tenus, en vertu du pr√©sent r√®glement, de se conformer aux exigences ciblant la cha√Æne de valeur de l‚Äô<span class="caps">IA</span> et, en particulier, aux exigences vis-√†-vis du fournisseur qui a utilis√© ce composant d‚Äô<span class="caps">IA</span> libre et ouvert. Les d√©veloppeurs de composants d‚Äô<span class="caps">IA</span> libres et ouverts devraient toutefois √™tre encourag√©s √† mettre en ≈ìuvre des pratiques documentaires largement adopt√©es, telles que <strong>des mod√®les et des cartes de donn√©es</strong>, afin d‚Äôacc√©l√©rer le partage d‚Äôinformations tout au long de la cha√Æne de valeur de l‚Äô<span class="caps">IA</span>, ce qui permettrait de promouvoir des syst√®mes d‚Äô<span class="caps">IA</span> dignes de confiance dans l‚ÄôUnion.</td>
</tr>
</tbody>
</table>
<p><strong>Commentaires:</strong>
La version anglaise utilise (de mani√®re factoris√©e et donc ambig√ºe) les termes &#8216;model cards&#8217; et &#8216;data cards&#8217; qui font r√©f√©rence √† des pratiques de documentation de mod√®les et de jeux de donn√©es en cours de formalisation et qui ont √©t√© introduits par M. Mitchell et ses co-auteurs dans: <a href="https://arxiv.org/abs/1810.03993">Model Cards for Model Reporting</a> et par M. Pushkarna et al dans <a href="https://dl.acm.org/doi/abs/10.1145/3531146.3533231">Data cards: Purposeful and transparent dataset documentation for responsible <span class="caps">AI</span></a> . La version fran√ßaise traduit &#8216;mod√®les et cartes de donn√©es&#8217;, un double contresens qui conduit √† perdre la notion de &#8216;carte (d&#8217;identit√©) du mod√®le&#8217;. Une traduction plus juste serait &#8216;carte d&#8217;identit√© du mod√®le&#8217; et &#8216;carte d&#8217;identit√© des&nbsp;donn√©es&#8217;.</p>
<p>Passons √† l&#8217;amendement&nbsp;(60e)</p>
<table>
<thead>
<tr>
<th>Anglais</th>
<th>Fran√ßais</th>
</tr>
</thead>
<tbody>
<tr>
<td>(60e) <strong>Foundation models</strong> are a recent development, in which <span class="caps">AI</span> models are developed from algorithms designed to optimize for generality and versatility of output. Those models are often <strong>trained</strong> on a broad range of data sources and large amounts of data to accomplish a wide range of <strong>downstream tasks</strong>, including some for which they were not specifically developed and trained. The foundation model can be unimodal or multimodal, trained through various methods such as supervised learning or reinforced learning. <span class="caps">AI</span> systems with specific intended purpose or general purpose <span class="caps">AI</span> systems can be an implementation of a foundation model, which means that each foundation model can be reused in countless downstream <span class="caps">AI</span> or general purpose <span class="caps">AI</span> systems. These models hold growing importance to many <strong>downstream application</strong>s and systems.</td>
<td>(60 sexies) Les <strong>syst√®mes d‚Äô<span class="caps">IA</span> √† finalit√© g√©n√©rale</strong> sont une √©volution r√©cente, dans le cadre de laquelle des mod√®les d‚Äô<span class="caps">IA</span> sont d√©velopp√©s √† partir d‚Äôalgorithmes con√ßus pour optimiser la g√©n√©ralit√© et la polyvalence de la production. Ces mod√®les sont souvent <strong>form√©s</strong> sur un large √©ventail de sources de donn√©es et de grandes quantit√©s de donn√©es pour accomplir un large √©ventail de <strong>t√¢ches en aval</strong>, y compris certaines pour lesquelles ils n‚Äôont pas √©t√© sp√©cifiquement d√©velopp√©s et <strong>form√©s</strong>. Le syst√®me d‚Äô<span class="caps">IA</span> √† finalit√© g√©n√©rale peut √™tre unimodal ou multimodal, form√© au moyen de diverses m√©thodes telles que l‚Äôapprentissage supervis√© ou l‚Äôapprentissage renforc√©. Les syst√®mes d‚Äô<span class="caps">IA</span> ayant une destination sp√©cifique ou les syst√®mes d‚Äô<span class="caps">IA</span> √† usage g√©n√©ral peuvent √™tre la mise en ≈ìuvre d‚Äôun syst√®me d‚Äô<span class="caps">IA</span> √† finalit√© g√©n√©rale, ce qui signifie que chaque syst√®me d‚Äô<span class="caps">IA</span> √† finalit√© g√©n√©rale peut √™tre r√©utilis√© dans d‚Äôinnombrables <strong>syst√®mes d‚Äô<span class="caps">IA</span> en aval</strong> ou √† usage g√©n√©ral. Ces mod√®les rev√™tent une importance croissante pour de nombreuses <strong>applications et syst√®mes en aval</strong>.</td>
</tr>
</tbody>
</table>
<p><strong>Commentaires:</strong></p>
<p><span class="quo">&#8216;</span><a href="https://www.arxiv.org/abs/2108.07258">Foundation models</a>&#8216; est une proposition r√©cente de l&#8217;<a href="https://hai.stanford.edu/">Institute for Human-Centered Artificial Intelligence</a> de Stanford qui ne fait pas compl√®tement consensus mais qui d√©signe sp√©cifiquement les mod√®les profonds pr√©entrain√©s (voir par exemple <a href="https://en.wikipedia.org/wiki/Foundation_models">Wikip√©dia</a>); la version fran√ßaise traduit de mani√®re assez syst√©matique &#8216;syst√®mes d&#8217;<span class="caps">IA</span> √† finalit√© g√©n√©rale&#8217;, qui est toutefois bien plus g√©n√©ral que &#8216;mod√®le de fondation&#8217; et pourrait aussi bien d√©signer des mod√®les probabilistes, symboliques ou hybrides. Cette traduction a le m√©rite de bien mettre en √©vidence le nouveau probl√®me pos√© par ces mod√®les (ils n&#8217;ont pas de finalit√© pr√©cise), mais la confusion f√¢cheurse entre &#8216;mod√®les&#8217; et &#8216;syst√®mes&#8217; rend la fin de ce paragraphe compl√®tement incompr√©hensible car le texte anglais explique qu&#8217;un mod√®le de fondation peut servir √† implanter des syst√®mes soit √† destination sp√©cifique, soit g√©n√©raux; comme les deux concepts sont confondus dans le texte fran√ßais, la derni√®re phrase du texte fran√ßais semble introduire une diff√©rence entre &#8216;syst√®mes √† finalit√© g√©n√©rale&#8217; et &#8216;syst√®mes √† usage&nbsp;g√©n√©ral&#8217;.</p>
<p><span class="quo">&#8216;</span>foundation(al) model&#8217; pourrait √™tre mieux traduit par &#8216;mod√®le de fondation&#8217; comme dans le r√©cent <a href="https://anr.fr/fr/france-2030/france2030/call/ia-cluster-poles-de-recherche-et-de-formation-de-rang-mondial-en-intelligence-artificielle-app/">appel de l&#8217;<span class="caps">ANR</span> sur les (sic) &#8216;<span class="caps">IA</span>-clusters&#8217; (p√¥les de recherche et formation en <span class="caps">IA</span>)</a>; c&#8217;est √©galement le terme retenu par le Comit√© National Pilote d&#8217;Ethique du Num√©rique (<span class="caps">CNPEN</span>) dans son r√©cent avis (7) sur les <a href="https://www.ccne-ethique.fr/sites/default/files/2023-07/CNPEN-Avis7.pdf">Intelligences Artificielles Gen√©ratives</a>.</p>
<p>Dans sa pr√©sentation des &#8216;mod√®les de fondation&#8217;, la version anglaise discute de leur apprentissage en termes g√©n√©raux. L&#8217;anglais utilise &#8216;supervised learning&#8217; et &#8216;reinforced learning&#8217;. Le second est probablement une erreur pour &#8216;reinforcement learning&#8217;, que le fran√ßais traduit par &#8216;apprentissage renforc√©&#8217; au lieu d&#8217;utiliser la terminologie √©tablie &#8216;apprentissage par renforcement&#8217;. Plus fondamentalement, il y a peut-√™tre ici un contresens dans la compr√©hension des &#8216;foundation models&#8217;, que l&#8217;article original de Stanford (section 1.1) caract√©rise pr√©cis√©ment par leur incompl√©tude, et par le fait qu&#8217;ils sont entra√Æn√©s sans&nbsp;supervision.</p>
<p><span class="quo">&#8216;</span>t√¢che en aval&#8217; est attest√©, mais c&#8217;est une traduction litt√©rale de &#8216;downstream task&#8217;, qui est typiquement utilis√©e pour d√©crire des applications qui impliquent une succession de traitement; &#8216;t√¢ches finales&#8217; serait sans doute meilleur pour marquer le fait qu&#8217;il s&#8217;agit d&#8217;applications&nbsp;finalis√©es.</p>
<p>Enfin, on note que &#8216;trained&#8217; est plusieurs fois traduit par &#8216;form√©(s)&#8217; (&#8216;souvent form√©s&#8217;, &#8216;d√©velopp√©s et form√©s&#8217;), √† la place de &#8216;entra√Æn√©(s)&#8217; qui est la traduction&nbsp;correcte.</p>
<hr>
<table>
<thead>
<tr>
<th>Anglais</th>
<th>Fran√ßais</th>
</tr>
</thead>
<tbody>
<tr>
<td>(60f)  In the case of <strong>foundation models provided as a service such as through <span class="caps">API</span> access</strong>, the cooperation with downstream providers should extend throughout the time during which that service is provided and supported, in order to enable appropriate risk mitigation, unless the provider of the foundation model transfers the training model as well as extensive and appropriate information on the datasets and the development process of the system or restricts the service, such as the <span class="caps">API</span> access, in such a way that the downstream provider is able to fully comply with this Regulation without further support from the original provider of the foundation model.</td>
<td>(60 septies) Dans le cas de <strong>syst√®mes d‚Äô<span class="caps">IA</span> √† finalit√© g√©n√©rale fournis sous la forme d‚Äôun service comme par acc√®s <span class="caps">API</span></strong>, la coop√©ration avec les fournisseurs en aval devrait s‚Äô√©tendre pendant toute la dur√©e de fourniture et de soutien de ce service, afin de permettre une att√©nuation appropri√©e des risques, √† moins que le fournisseur du syst√®me d‚Äô<span class="caps">IA</span> √† finalit√© g√©n√©rale ne transf√®re le syst√®me d‚Äô<span class="caps">IA</span> √† finalit√© g√©n√©rale ainsi que des informations d√©taill√©es et appropri√©es sur les ensembles de donn√©es et le processus de d√©veloppement du syst√®me ou restreint le service, comme l‚Äôacc√®s <span class="caps">API</span>, de mani√®re √† ce que le fournisseur en aval soit en mesure de se conformer pleinement au pr√©sent r√®glement sans le soutien suppl√©mentaire du fournisseur initial du syst√®me d‚Äô<span class="caps">IA</span> √† finalit√© g√©n√©rale.</td>
</tr>
</tbody>
</table>
<p><span class="quo">&#8216;</span>comme par acc√®s <span class="caps">API</span>&#8217; (such as through <span class="caps">API</span>) n&#8217;est pas tr√®s heureux - en √©cho √† &#8216;software as a service&#8217; / logiciel en tant que service, on pourrait sugg√©rer &#8216;mod√®les de fondation en tant que services fournis au travers d&#8217;<span class="caps">API</span>&#8217;. On note qu&#8217;il existe un terme recommand√© pour <span class="caps">API</span>: <a href="https://www.culture.fr/franceterme/terme/INFO960?domaine=0&amp;q=API">Interface de Programmation&nbsp;d&#8217;Application</a></p>
<p><span class="quo">&#8216;</span>downstream providers&#8217; - fournisseurs en aval, voir commentaire&nbsp;supra.</p>
<p>Poursuivons la lecture avec l&#8217;amendement&nbsp;suivant.</p>
<table>
<thead>
<tr>
<th>Anglais</th>
<th>Fran√ßais</th>
</tr>
</thead>
<tbody>
<tr>
<td>60g)  In light of the nature and complexity of the value chain for <span class="caps">AI</span> system, it is essential to clarify the role of actors contributing to the development of <span class="caps">AI</span> systems. There is significant uncertainty as to the way foundation models will evolve, both in terms of typology of models and in terms of self-governance. Therefore, it is essential to clarify the legal situation of providers of foundation models. Combined with their complexity and unexpected impact, the downstream <span class="caps">AI</span> provider‚Äôs lack of control over the foundation model‚Äôs development and the consequent power imbalance and in order to ensure a fair sharing of responsibilities along the <span class="caps">AI</span> value chain, such models should be subject to proportionate and more specific requirements and obligations under this Regulation, namely foundation models should assess and mitigate possible risks and harms through appropriate design, testing and analysis, should implement data governance measures, including assessment of biases, and should comply with technical design requirements to ensure appropriate levels of performance, predictability, interpretability, corrigibility, safety and cybersecurity and should comply with environmental standards. These obligations should be accompanied by standards. Also, foundation models should have information obligations and prepare all necessary technical documentation for potential downstream providers to be able to comply with their obligations under this Regulation. Generative foundation models should ensure transparency about the fact the content is generated by an <span class="caps">AI</span> system, not by humans. These specific requirements and obligations do not amount to considering foundation models as high risk <span class="caps">AI</span> systems, but should guarantee that the objectives of this Regulation to ensure a high level of protection of fundamental rights, health and safety, environment, demoacracy and rule of law are achieved. <strong>Pre-trained</strong> models developed for a narrower, less general, more limited set of applications that cannot be adapted for a wide range of tasks such as <strong>simple multi-purpose <span class="caps">AI</span> systems</strong> should not be considered foundation models for the purposes of this Regulation, because of their greater <strong>interpretability</strong> which makes their behaviour less unpredictable.</td>
<td>(60 octies) Compte tenu de la nature et de la complexit√© de la cha√Æne de valeur des syst√®mes d‚Äô<span class="caps">IA</span>, il est essentiel de faire la lumi√®re sur le r√¥le des acteurs qui contribuent au d√©veloppement des syst√®me d‚Äô<span class="caps">IA</span>. Il existe une grande incertitude quant √† la mani√®re dont les syst√®mes d‚Äô<span class="caps">IA</span> √† finalit√© g√©n√©rale √©volueront, tant en ce qui concerne la typologie des mod√®les que l‚Äôautogouvernance. Il est donc essentiel de clarifier la situation juridique des fournisseurs de syst√®mes d‚Äô<span class="caps">IA</span> √† finalit√© g√©n√©rale. Combin√©s √† leur complexit√© et √† leur incidence inattendue, le manque de contr√¥le exerc√© par le fournisseur d‚Äô<span class="caps">IA</span> en aval sur le d√©veloppement du syst√®me d‚Äô<span class="caps">IA</span> √† finalit√© g√©n√©rale et sur le d√©s√©quilibre de pouvoir qui en r√©sulte, et afin de garantir un partage √©quitable des responsabilit√©s tout au long de la cha√Æne de valeur de l‚Äô<span class="caps">IA</span>, ces mod√®les devraient √™tre soumis √† des exigences et obligations proportionn√©es et plus sp√©cifiques au titre du pr√©sent r√®glement, √† savoir que les syst√®mes d‚Äô<span class="caps">IA</span> √† finalit√© g√©n√©rale devraient √©valuer et att√©nuer les risques et les pr√©judices √©ventuels au moyen d‚Äôune conception, d‚Äôessais et d‚Äôanalyses appropri√©s, mettre en ≈ìuvre des mesures de gouvernance des donn√©es, y compris l‚Äô√©valuation des biais, et respecter les exigences en mati√®re de conception technique afin de garantir des niveaux appropri√©s de performance, de pr√©visibilit√©, d‚Äôinterpr√©tation, de pr√©visibilit√©, de s√©curit√© et de cybers√©curit√©, et devraient √™tre conformes aux normes environnementales. Ces obligations devraient s‚Äôaccompagner de normes. En outre, les syst√®mes d‚Äô<span class="caps">IA</span> √† finalit√© g√©n√©rale devraient √™tre soumis √† des obligations d‚Äôinformation et pr√©parer toute la documentation technique n√©cessaire pour permettre aux fournisseurs en aval potentiels de se conformer aux obligations qui leur incombent en vertu du pr√©sent r√®glement. Les syst√®mes d‚Äô<span class="caps">IA</span> √† finalit√© g√©n√©rale g√©n√©ratifs devraient garantir la transparence quant au fait que le contenu est g√©n√©r√© par un syst√®me d‚Äô<span class="caps">IA</span>, et non par un humain. Ces exigences et obligations sp√©cifiques n‚Äô√©quivalent pas √† consid√©rer les syst√®mes d‚Äô<span class="caps">IA</span> √† finalit√© g√©n√©rale comme des syst√®mes d‚Äô<span class="caps">IA</span> √† haut risque, mais devraient garantir que les objectifs du pr√©sent r√®glement visant √† garantir un niveau √©lev√© de protection des droits fondamentaux, de la sant√© et de la s√©curit√©, de l‚Äôenvironnement, de la d√©mocratie et de l‚Äô√©tat de droit sont atteints. Les <strong>mod√®les pr√©form√©s</strong> √©labor√©s pour un ensemble d‚Äôapplications plus restreint, moins g√©n√©ral et plus limit√©, qui ne peuvent √™tre adapt√©s √† un large √©ventail de t√¢ches, telles que les simples syst√®mes d‚Äô<span class="caps">IA</span> polyvalents, ne devraient pas √™tre consid√©r√©s comme des syst√®mes d‚Äô<span class="caps">IA</span> √† finalit√© g√©n√©rale aux fins du pr√©sent r√®glement, en raison de leur plus grande <strong>capacit√© d‚Äôinterpr√©tation</strong>, ce qui rend leur comportement moins impr√©visible.</td>
</tr>
</tbody>
</table>
<hr>
<p><strong>Commentaire:</strong> En plus de la reprise de confusions qui existent dans les sections pr√©c√©dentes et la reprise de &#8216;pr√©form√©s&#8217; au lieu de &#8216;pr√©entra√Æn√©s&#8217;, la version fran√ßaise comporte une erreur de grammaire dans la derni√®re phrase &#8216;mod√®les pr√©form√©s (&#8230;), telles (=&gt; tels) que les simples syst√®mes polyvalents (&#8230;) ne devraient pas √™tre&nbsp;consid√©r√©s.&#8217;</p>
<p>Un contresens s&#8217;est gliss√© dans la derni√®re phrase: l&#8217;anglais parle &#8216;d&#8217;interpr√©tabilit√©&#8217; (&#8216;greater interpretability&#8217;), sans doute de mani√®re un peu hasardeuse car il sera difficile de dresser une fronti√®re claire entre ce qui est consid√©r√© comme mod√®le de fondation et ce qui ne l&#8217;est pas; le fran√ßais parle &#8216;d&#8217;interpr√©tation&#8217;, comme si les mod√®les dont il est question pouvaient produire des interpr√©tations de leurs sorties. Le lien qui est tiss√© ici entre &#8216;interpr√©tabilit√©&#8217; et &#8216;impr√©dictabilit√©&#8217; n&#8217;est pas tr√®s&nbsp;clair.</p>
<p>Le texte introduit enfin (peut-√™tre) un nouveau concept &#8216;simple multi-purpose <span class="caps">AI</span> systems&#8217; (donc un syst√®me qui n&#8217;a pas qu&#8217;une seule finalit√©, mais plusieurs, contrairement √† un syst√®me &#8216;√† finalit√©&nbsp;g√©n√©rale&#8217;).</p>
<hr>
<table>
<thead>
<tr>
<th>Anglais</th>
<th>Fran√ßais</th>
</tr>
</thead>
<tbody>
<tr>
<td>60h)  Given the nature of foundation models, expertise in conformity assessment is lacking and third-party auditing methods are still under development. The sector itself is therefore developing new ways to assess <strong>fundamental models</strong> that fulfil in part the objective of auditing (such as model evaluation, <strong>red-teaming</strong> or <strong>machine learning verification and validation techniques</strong>). Those internal assessments for foundation models should be should be broadly applicable (e.g. independent of distribution channels, modality, development methods), to address risks specific to such models taking into account industry state-of-the-art practices and focus on developing sufficient technical understanding and control over the model, the management of reasonably foreseeable risks, and extensive analysis and testing of the model through appropriate measures, such as by the involvement of independent evaluators. As foundation models are a new and fast-evolving development in the field of artificial intelligence, it is appropriate for the Commission and the <span class="caps">AI</span> Office to monitor and periodically asses the legislative and governance framework of such models and in particular of generative <span class="caps">AI</span> systems based on such models, which raise significant questions related to the generation of content in breach of Union law, copyright rules, and potential misuse. It should be clarified that this Regulation should be without prejudice to Union law on copyright and related rights, including Directives 2001/29/<span class="caps">EC</span>, 2004/48/<span class="caps">ECR</span> and (<span class="caps">EU</span>) 2019/790 of the European Parliament and of the Council.</td>
<td>(60 nonies) Compte tenu de la nature des syst√®mes d‚Äô<span class="caps">IA</span> √† finalit√© g√©n√©rale, l‚Äôexpertise en mati√®re d‚Äô√©valuation de la conformit√© fait d√©faut et des m√©thodes d‚Äôaudit par des tiers sont toujours en cours d‚Äô√©laboration. Le secteur lui-m√™me d√©veloppe donc de nouveaux moyens d‚Äô√©valuer les syst√®mes d‚Äô<span class="caps">IA</span> √† finalit√© g√©n√©rale qui r√©pondent en partie √† l‚Äôobjectif de l‚Äôaudit (tels que l‚Äô√©valuation des mod√®les, la <strong>m√©thode de l‚Äô√©quipe rouge (¬´red teaming¬ª)</strong> ou les <strong>techniques de v√©rification et de validation de l‚Äôapprentissage automatique</strong>). Ces √©valuations internes des syst√®mes d‚Äô<span class="caps">IA</span> √† finalit√© g√©n√©rale devraient √™tre largement applicables (par exemple, ind√©pendamment des canaux de distribution, des modalit√©s, des m√©thodes de d√©veloppement), afin de traiter les risques propres √† ces mod√®les en tenant compte des pratiques les plus r√©centes du secteur et de mettre l‚Äôaccent sur le d√©veloppement d‚Äôune compr√©hension technique et d‚Äôun contr√¥le suffisants du mod√®le, sur la gestion des risques raisonnablement pr√©visibles, ainsi que sur une analyse et des essais approfondis du mod√®le au moyen de mesures appropri√©es, par exemple par la participation d‚Äô√©valuateurs ind√©pendants. √âtant donn√© que les syst√®mes d‚Äô<span class="caps">IA</span> √† finalit√© g√©n√©rale constituent une √©volution nouvelle et rapide dans le domaine de l‚Äôintelligence artificielle, il convient que la Commission et le Bureau de l‚Äô<span class="caps">IA</span> surveillent et √©valuent p√©riodiquement le cadre l√©gislatif et de gouvernance de ces mod√®les et, en particulier, des syst√®mes d‚Äô<span class="caps">IA</span> g√©n√©ratifs fond√©s sur de tels mod√®les, qui soul√®vent des questions importantes li√©es √† la production de contenus en violation du droit de l‚ÄôUnion, aux r√®gles en mati√®re de droit d‚Äôauteur et √† d‚Äô√©ventuels abus. Il convient de pr√©ciser que le pr√©sent r√®glement devrait √™tre sans pr√©judice du droit de l‚ÄôUnion sur le droit d‚Äôauteur et les droits voisins, y compris les directives 2001/29/<span class="caps">CE</span>, 2004/48/<span class="caps">CE</span> et (<span class="caps">UE</span>) 2019/790 du Parlement europ√©en et du Conseil.</td>
</tr>
</tbody>
</table>
<p><strong>Commentaire:</strong></p>
<p>Une erreur ou confusion peut-√™tre dans le texte anglais qui parle maintenant de &#8216;fundamental model&#8217;, pour lequel le fran√ßais conserve &#8216;syst√®me d&#8217;<span class="caps">IA</span> √† finalit√©&nbsp;g√©n√©rale&#8217;. </p>
<p><span class="quo">&#8216;</span>red-teaming&#8217; est traduit de mani√®re litt√©rale par &#8216;l&#8217;√©quipe rouge&#8217;, mais les traducteurs ont pris soin de rappeler le terme anglais. En s√©curit√© informatique &#8220;red-teaming&#8221; renvoie aux strat√©gies de mises √† l&#8217;√©preuve de syst√®mes qui emploient des m√©thodes adverses, en essayant de simuler ce que ferait un agresseur de l&#8217;<a href="https://fr.wikipedia.org/wiki/%C3%89quipe_rouge">√©quipe rouge</a> (la &#8220;red-team&#8221; d√©signant souvent en langage militaire l&#8217;ennemi, et la &#8220;blue-team&#8221; les alli√©s). Il est douteux que cette interpr√©tation soit tr√®s bien connue - une traduction possiblement plus transparente serait dans le contexte &#8216;(..) l&#8217;√©tude de leur comportement face √† des attaques malveillantes&#8217; etc. Le texte continue par un contresens, &#8216;techniques de v√©rification et validation de l&#8217;apprentissage automatique&#8217; quand l&#8217;anglais dit  &#8216;techniques d&#8217;apprentissage automatique pour la v√©rification et la&nbsp;validation&#8217;.</p>
    </div>
  </article>
    </div>
  </div>

  <footer class="footer">
    <div class="container">
<div class="row">
  <!-- <ul class="col-sm-6 list-inline"> -->
    <!-- <li class="list-inline-item"><a href="https://anr-matos.github.io/en/archives.html">Archives</a></li> -->
    <!-- <li class="list-inline-item"><a href="https://anr-matos.github.io/en/pages/categories">Categories</a></li> -->
  <!-- </ul> -->

  <ul id="logos" class="list-group list-group-horizontal container-fluid borderless">
    <li class="list-group-item p-3"><img src="https://anr-matos.github.io/en/static/images/CNRS.png"></li>
    <li class="list-group-item p-3"><img src="https://anr-matos.github.io/en/static/images/Logo-sorbonne.jpg"></li>
    <li class="list-group-item p-3"><img src="https://anr-matos.github.io/en/static/images/inria.png"></li>
    <li class="list-group-item p-3"><img src="https://anr-matos.github.io/en/static/images/Universite_Paris-Cite-logo.jpeg"></li>
    <li class="list-group-item p-3 ml-auto"><img src="https://anr-matos.github.io/en/static/images/Logo-ANR.jpg"></li>
  </ul>
  
  <p class="col-sm-6 text-sm-left text-muted">
    Generated by <a href="https://github.com/getpelican/pelican" target="_blank">Pelican</a>
    / <a href="https://github.com/nairobilug/pelican-alchemy" target="_blank">&#x2728;</a>
  </p>
</div>    </div>
  </footer>



    <!-- jQuery library -->
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.7.1/dist/jquery.slim.min.js"></script>
    <!-- Popper JS -->
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"></script>
    <!-- Latest compiled JavaScript -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script>
    <script src="https://anr-matos.github.io/en/theme/js/copy_to_clipboard.js"></script>
    
</body>

</html>